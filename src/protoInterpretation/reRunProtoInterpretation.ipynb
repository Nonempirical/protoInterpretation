{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oHCoF1OsxIt"
      },
      "source": [
        "### Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGbh0Xkq-xCZ",
        "outputId": "0030f101-b9af-40c7-da4b-63dd010f95f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wpgWH_nstLr"
      },
      "source": [
        "### Connect to git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QVtqZrr9-x-G",
        "outputId": "4fa5a409-6ba9-41c2-bb86-5bd40836fd52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'protoInterpretation'...\n",
            "remote: Enumerating objects: 122, done.\u001b[K\n",
            "remote: Counting objects: 100% (122/122), done.\u001b[K\n",
            "remote: Compressing objects: 100% (71/71), done.\u001b[K\n",
            "remote: Total 122 (delta 59), reused 98 (delta 35), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (122/122), 53.04 KiB | 17.68 MiB/s, done.\n",
            "Resolving deltas: 100% (59/59), done.\n",
            "/content/protoInterpretation\n",
            "Obtaining file:///content/protoInterpretation\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from protoInterpretation==0.1.0) (2.9.0+cu126)\n",
            "Requirement already satisfied: transformers>=4.30.0 in /usr/local/lib/python3.12/dist-packages (from protoInterpretation==0.1.0) (4.57.3)\n",
            "Requirement already satisfied: umap-learn>=0.5.3 in /usr/local/lib/python3.12/dist-packages (from protoInterpretation==0.1.0) (0.5.9.post2)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from protoInterpretation==0.1.0) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.24.0 in /usr/local/lib/python3.12/dist-packages (from protoInterpretation==0.1.0) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from protoInterpretation==0.1.0) (1.6.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->protoInterpretation==0.1.0) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->protoInterpretation==0.1.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->protoInterpretation==0.1.0) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->protoInterpretation==0.1.0) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->protoInterpretation==0.1.0) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->protoInterpretation==0.1.0) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->protoInterpretation==0.1.0) (3.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->protoInterpretation==0.1.0) (2.9.0.post0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.3.0->protoInterpretation==0.1.0) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.3.0->protoInterpretation==0.1.0) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.3.0->protoInterpretation==0.1.0) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->protoInterpretation==0.1.0) (3.20.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->protoInterpretation==0.1.0) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->protoInterpretation==0.1.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->protoInterpretation==0.1.0) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->protoInterpretation==0.1.0) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->protoInterpretation==0.1.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->protoInterpretation==0.1.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->protoInterpretation==0.1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->protoInterpretation==0.1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->protoInterpretation==0.1.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->protoInterpretation==0.1.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->protoInterpretation==0.1.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->protoInterpretation==0.1.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->protoInterpretation==0.1.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->protoInterpretation==0.1.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->protoInterpretation==0.1.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->protoInterpretation==0.1.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->protoInterpretation==0.1.0) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->protoInterpretation==0.1.0) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->protoInterpretation==0.1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->protoInterpretation==0.1.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->protoInterpretation==0.1.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->protoInterpretation==0.1.0) (3.5.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.30.0->protoInterpretation==0.1.0) (0.36.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.30.0->protoInterpretation==0.1.0) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.30.0->protoInterpretation==0.1.0) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers>=4.30.0->protoInterpretation==0.1.0) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.30.0->protoInterpretation==0.1.0) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.30.0->protoInterpretation==0.1.0) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.30.0->protoInterpretation==0.1.0) (4.67.1)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.12/dist-packages (from umap-learn>=0.5.3->protoInterpretation==0.1.0) (0.60.0)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.12/dist-packages (from umap-learn>=0.5.3->protoInterpretation==0.1.0) (0.6.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.30.0->protoInterpretation==0.1.0) (1.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.2->umap-learn>=0.5.3->protoInterpretation==0.1.0) (0.43.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7.0->protoInterpretation==0.1.0) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->protoInterpretation==0.1.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->protoInterpretation==0.1.0) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.30.0->protoInterpretation==0.1.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.30.0->protoInterpretation==0.1.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.30.0->protoInterpretation==0.1.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.30.0->protoInterpretation==0.1.0) (2026.1.4)\n",
            "Installing collected packages: protoInterpretation\n",
            "  Running setup.py develop for protoInterpretation\n",
            "Successfully installed protoInterpretation-0.1.0\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Nonempirical/protoInterpretation.git\n",
        "%cd protoInterpretation\n",
        "!pip install -e .\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xStMUv2vpeu9"
      },
      "source": [
        "### Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oB6iFY9Ppjia"
      },
      "outputs": [],
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "from google.colab import drive\n",
        "from src.protoInterpretation import find_runs_directory, scan_runs\n",
        "\n",
        "# Mount Drive\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "# Find runs directory\n",
        "PROJECT_FOLDER_NAME = \"protoInterpretation-runs\"\n",
        "search_roots = [\"/content/drive/MyDrive\", \"/content/drive/shared-with-me\"]\n",
        "\n",
        "BASE_RUN_DIR = None\n",
        "for root in search_roots:\n",
        "    found = find_runs_directory(root, folder_name=PROJECT_FOLDER_NAME)\n",
        "    if found:\n",
        "        BASE_RUN_DIR = found\n",
        "        break\n",
        "\n",
        "if BASE_RUN_DIR is None:\n",
        "    raise RuntimeError(f\"Could not find '{PROJECT_FOLDER_NAME}' folder\")\n",
        "\n",
        "# Scan runs\n",
        "runs = scan_runs(BASE_RUN_DIR)\n",
        "run_names = sorted(runs.keys())\n",
        "\n",
        "print(f\"Found {len(run_names)} runs\")\n",
        "\n",
        "# --- NEW: \"Run all prompts\" option ---\n",
        "RUN_ALL = \"__RUN_ALL__\"\n",
        "\n",
        "# Use (label, value) pairs so the displayed text can be friendly\n",
        "run_options = [(\"\", \"\"), (\"Run all prompts\", RUN_ALL)] + [(name, name) for name in run_names]\n",
        "\n",
        "dropdowns = [\n",
        "    widgets.Dropdown(\n",
        "        options=run_options,\n",
        "        value=\"\",\n",
        "        description=f\"Run {chr(65+i)}:\",\n",
        "        layout=widgets.Layout(width=\"300px\")\n",
        "    )\n",
        "    for i in range(10)\n",
        "]\n",
        "\n",
        "def _on_any_dropdown_change(change):\n",
        "    if change.get(\"name\") != \"value\":\n",
        "        return\n",
        "    all_selected = any(dd.value == RUN_ALL for dd in dropdowns)\n",
        "    if all_selected:\n",
        "        # Optional UI polish: disable other dropdowns when \"Run all prompts\" is active\n",
        "        for dd in dropdowns:\n",
        "            dd.disabled = (dd.value != RUN_ALL)\n",
        "    else:\n",
        "        for dd in dropdowns:\n",
        "            dd.disabled = False\n",
        "\n",
        "for dd in dropdowns:\n",
        "    dd.observe(_on_any_dropdown_change, names=\"value\")\n",
        "\n",
        "def get_selected_run_names():\n",
        "    \"\"\"Call this in later cells to get the final list of runs to process.\"\"\"\n",
        "    if any(dd.value == RUN_ALL for dd in dropdowns):\n",
        "        return run_names  # all runs\n",
        "    # otherwise: unique, non-empty selections (keep order)\n",
        "    selected = []\n",
        "    seen = set()\n",
        "    for dd in dropdowns:\n",
        "        v = dd.value\n",
        "        if v and v not in seen:\n",
        "            seen.add(v)\n",
        "            selected.append(v)\n",
        "    return selected\n",
        "\n",
        "rows = [widgets.HBox(dropdowns[i:i+2]) for i in range(0, len(dropdowns), 2)]\n",
        "\n",
        "display(widgets.VBox([\n",
        "    widgets.HTML(\"<h3>Select Runs to Visualize</h3>\"),\n",
        "    *rows\n",
        "]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0L1JP7KwqHNL"
      },
      "source": [
        "### Entropy plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "lFRddnbxLXmx",
        "outputId": "18f0b41b-0027-498d-c624-e84d2befc8c6"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "`runs` is not defined. Run the scan_runs cell first.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-240857585.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"runs\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`runs` is not defined. Run the scan_runs cell first.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m PROMPT_PAIRS = [\n",
            "\u001b[0;31mRuntimeError\u001b[0m: `runs` is not defined. Run the scan_runs cell first."
          ]
        }
      ],
      "source": [
        "# Open + Closed entropy plots with COMMON x/y axis limits + APA-style titles\n",
        "# (and x-axis starts slightly before 0)\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from src.protoInterpretation import run_name_to_display, load_run_by_name\n",
        "\n",
        "if \"runs\" not in globals():\n",
        "    raise RuntimeError(\"`runs` is not defined. Run the scan_runs cell first.\")\n",
        "\n",
        "PROMPT_PAIRS = [\n",
        "    (\"A bat is\", \"A pencil is\"),\n",
        "    (\"The woman in the blue dress\", \"Napoleon is\"),\n",
        "    (\"I saw\", \"Photosynthesis is the process where\"),\n",
        "    (\"Something happens when there exists\", \"The declaration of Independence formally\"),\n",
        "    (\"The man\", \"Photosynthesis is\"),\n",
        "    (\"The man in the street\", \"Erosion is\"),\n",
        "]\n",
        "OPEN_PROMPTS = [p[0] for p in PROMPT_PAIRS]\n",
        "CLOSED_PROMPTS = [p[1] for p in PROMPT_PAIRS]\n",
        "\n",
        "def _norm(s: str) -> str:\n",
        "    return \" \".join(str(s).strip().lower().split())\n",
        "\n",
        "def set_apa_title(fig, title_text, *, y=0.98):\n",
        "    title = str(title_text).strip()\n",
        "    if title.endswith(\".\"):\n",
        "        title = title[:-1]\n",
        "    fig.text(0.01, y, title, ha=\"left\", va=\"top\", fontsize=11, fontstyle=\"italic\")\n",
        "\n",
        "open_keys = [_norm(p) for p in OPEN_PROMPTS]\n",
        "closed_keys = [_norm(p) for p in CLOSED_PROMPTS]\n",
        "\n",
        "# Candidate runs: if dropdowns exists and has selections -> restrict; else all runs\n",
        "candidate_run_names = list(runs.keys())\n",
        "if \"dropdowns\" in globals():\n",
        "    picked = [getattr(d, \"value\", \"\") for d in dropdowns if getattr(d, \"value\", \"\")]\n",
        "    picked = list(dict.fromkeys([p for p in picked if p]))\n",
        "    if picked:\n",
        "        candidate_run_names = picked\n",
        "\n",
        "# Pick latest run per prompt (by timestamp sort in folder name)\n",
        "runs_for_key = {k: [] for k in set(open_keys + closed_keys)}\n",
        "for rn in candidate_run_names:\n",
        "    k = _norm(run_name_to_display(rn))\n",
        "    if k in runs_for_key:\n",
        "        runs_for_key[k].append(rn)\n",
        "\n",
        "chosen_for_key = {k: max(v) for k, v in runs_for_key.items() if v}\n",
        "\n",
        "open_runs = [chosen_for_key[k] for k in open_keys if k in chosen_for_key]\n",
        "closed_runs = [chosen_for_key[k] for k in closed_keys if k in chosen_for_key]\n",
        "if not open_runs or not closed_runs:\n",
        "    raise RuntimeError(\"Missing runs for open or closed prompts (check run names / prompt text matching).\")\n",
        "\n",
        "# Load metrics for both groups\n",
        "metrics_open = {}\n",
        "metrics_closed = {}\n",
        "\n",
        "for k in open_keys:\n",
        "    rn = chosen_for_key.get(k)\n",
        "    if rn:\n",
        "        _, m = load_run_by_name(rn, runs, compute_metrics=True)\n",
        "        metrics_open[rn] = m\n",
        "\n",
        "for k in closed_keys:\n",
        "    rn = chosen_for_key.get(k)\n",
        "    if rn:\n",
        "        _, m = load_run_by_name(rn, runs, compute_metrics=True)\n",
        "        metrics_closed[rn] = m\n",
        "\n",
        "# Shared axis limits across BOTH plots\n",
        "all_means = []\n",
        "max_T = 0\n",
        "for m in list(metrics_open.values()) + list(metrics_closed.values()):\n",
        "    y = m.entropy.mean\n",
        "    if len(y):\n",
        "        all_means.append(y)\n",
        "        max_T = max(max_T, len(y))\n",
        "\n",
        "y_all = np.concatenate(all_means)\n",
        "y_min, y_max = float(y_all.min()), float(y_all.max())\n",
        "y_pad = 0.05 * (y_max - y_min) if y_max > y_min else 0.25\n",
        "Y_LIM = (y_min - y_pad, y_max + y_pad)\n",
        "\n",
        "# x starts before 0 for readability\n",
        "X_LIM = (-0.5, max_T - 1)\n",
        "\n",
        "def plot_group(metrics_dict, title_text):\n",
        "    fig, ax = plt.subplots(figsize=(7, 4))\n",
        "\n",
        "    for rn, m in metrics_dict.items():\n",
        "        label = run_name_to_display(rn)\n",
        "        y = m.entropy.mean\n",
        "        ax.plot(np.arange(len(y)), y, linewidth=2, alpha=0.9, label=label)\n",
        "\n",
        "    ax.set_xlim(*X_LIM)\n",
        "    ax.set_ylim(*Y_LIM)\n",
        "    ax.set_xlabel(\"Step\")\n",
        "    ax.set_ylabel(\"Entropy (bits)\")\n",
        "    ax.set_title(\"\")  # title handled by set_apa_title\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    ax.legend(loc=\"best\", fontsize=8, frameon=True)\n",
        "\n",
        "    fig.tight_layout(rect=[0, 0, 1, 0.92])\n",
        "    set_apa_title(fig, title_text)\n",
        "    plt.show()\n",
        "\n",
        "plot_group(metrics_open, \"Predictive Entropy Across Generation Steps for Open Prompts\")\n",
        "plot_group(metrics_closed, \"Predictive Entropy Across Generation Steps for Closed Prompts\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLMhkczPqM9a"
      },
      "source": [
        "### Create UMAP's"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iz3jdgPcGe_b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "\n",
        "# Prefer installed package name; fall back to repo import\n",
        "try:\n",
        "    from src.protoInterpretation import (\n",
        "        run_name_to_display,\n",
        "        load_embeddings_from_runs,\n",
        "        compute_global_umap,\n",
        "    )\n",
        "except ImportError:\n",
        "    from src.protoInterpretation import (\n",
        "        run_name_to_display,\n",
        "        load_embeddings_from_runs,\n",
        "        compute_global_umap,\n",
        "    )\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# MUST exist from previous cells:\n",
        "# - runs (dict from scan_runs)\n",
        "# ------------------------------------------------------------\n",
        "if \"runs\" not in globals():\n",
        "    raise RuntimeError(\"`runs` is not defined. Run the scan_runs cell first.\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Table X (Open first, Closed second)\n",
        "# ------------------------------------------------------------\n",
        "PROMPT_PAIRS = [\n",
        "    (\"A bat is\", \"A pencil is\"),\n",
        "    (\"The woman in the blue dress\", \"Napoleon is\"),\n",
        "    (\"I saw\", \"Photosynthesis is the process where\"),\n",
        "    (\"Something happens when there exists\", \"The declaration of Independence formally\"),\n",
        "    (\"The man\", \"Photosynthesis is\"),\n",
        "    (\"The man in the street\", \"Erosion is\"),\n",
        "]\n",
        "OPEN_PROMPTS = [p[0] for p in PROMPT_PAIRS]\n",
        "CLOSED_PROMPTS = [p[1] for p in PROMPT_PAIRS]\n",
        "\n",
        "def _norm(s: str) -> str:\n",
        "    return \" \".join(str(s).strip().lower().split())\n",
        "\n",
        "open_keys = [_norm(p) for p in OPEN_PROMPTS]\n",
        "closed_keys = [_norm(p) for p in CLOSED_PROMPTS]\n",
        "all_keys_in_pair_order = [k for pair in PROMPT_PAIRS for k in (_norm(pair[0]), _norm(pair[1]))]\n",
        "\n",
        "key_to_prompt = {k: p for k, p in zip(open_keys, OPEN_PROMPTS)}\n",
        "key_to_prompt.update({k: p for k, p in zip(closed_keys, CLOSED_PROMPTS)})\n",
        "\n",
        "key_to_group = {k: \"open\" for k in open_keys}\n",
        "key_to_group.update({k: \"closed\" for k in closed_keys})\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Styling (consistent)\n",
        "# ------------------------------------------------------------\n",
        "OPEN_COLOR = \"#1f77b4\"    # blue\n",
        "CLOSED_COLOR = \"#ff7f0e\"  # orange\n",
        "POINT_ALPHA = 0.65\n",
        "POINT_SIZE = 8\n",
        "\n",
        "def set_apa_title(fig, title_text, *, y=0.98):\n",
        "    title = str(title_text).strip()\n",
        "    if title.endswith(\".\"):\n",
        "        title = title[:-1]\n",
        "    fig.text(0.01, y, title, ha=\"left\", va=\"top\", fontsize=11, fontstyle=\"italic\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# UMAP settings\n",
        "# ------------------------------------------------------------\n",
        "UMAP_STEP_WANTED = 31\n",
        "UMAP_METRIC = \"cosine\"\n",
        "UMAP_SEED = 42\n",
        "L2_NORMALIZE = True\n",
        "PCA_COMPONENTS = 50\n",
        "UMAP_N_NEIGHBORS = 15\n",
        "UMAP_MIN_DIST = 0.1\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Candidate runs: if dropdowns exists and has selections -> restrict; else all runs\n",
        "# ------------------------------------------------------------\n",
        "candidate_run_names = list(runs.keys())\n",
        "if \"dropdowns\" in globals():\n",
        "    picked = [getattr(d, \"value\", \"\") for d in dropdowns if getattr(d, \"value\", \"\")]\n",
        "    picked = list(dict.fromkeys([p for p in picked if p]))\n",
        "    if picked:\n",
        "        candidate_run_names = picked\n",
        "        print(f\"Using {len(candidate_run_names)} candidate runs (from dropdowns).\")\n",
        "    else:\n",
        "        print(f\"Using {len(candidate_run_names)} candidate runs (all runs).\")\n",
        "else:\n",
        "    print(f\"Using {len(candidate_run_names)} candidate runs (all runs).\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Match latest run per prompt (by timestamp sorting in run folder name)\n",
        "# ------------------------------------------------------------\n",
        "target_keys = set(open_keys + closed_keys)\n",
        "runs_for_key = {k: [] for k in target_keys}\n",
        "\n",
        "for rn in candidate_run_names:\n",
        "    disp = run_name_to_display(rn)\n",
        "    k = _norm(disp)\n",
        "    if k in runs_for_key:\n",
        "        runs_for_key[k].append(rn)\n",
        "\n",
        "chosen_for_key = {}\n",
        "for k, lst in runs_for_key.items():\n",
        "    if lst:\n",
        "        chosen_for_key[k] = max(lst)  # newest run\n",
        "\n",
        "open_runs = [chosen_for_key[k] for k in open_keys if k in chosen_for_key]\n",
        "closed_runs = [chosen_for_key[k] for k in closed_keys if k in chosen_for_key]\n",
        "all_runs_pair_order = [chosen_for_key[k] for k in all_keys_in_pair_order if k in chosen_for_key]\n",
        "\n",
        "if not all_runs_pair_order:\n",
        "    raise RuntimeError(\"No matching runs found for Table X prompts. Check run names / prompts.\")\n",
        "\n",
        "print(f\"Matched runs: open={len(open_runs)}, closed={len(closed_runs)}, total={len(all_runs_pair_order)}\")\n",
        "\n",
        "run_to_group = {}\n",
        "run_to_prompt = {}\n",
        "for k in open_keys:\n",
        "    rn = chosen_for_key.get(k)\n",
        "    if rn:\n",
        "        run_to_group[rn] = \"open\"\n",
        "        run_to_prompt[rn] = key_to_prompt[k]\n",
        "for k in closed_keys:\n",
        "    rn = chosen_for_key.get(k)\n",
        "    if rn:\n",
        "        run_to_group[rn] = \"closed\"\n",
        "        run_to_prompt[rn] = key_to_prompt[k]\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Output folder\n",
        "# ------------------------------------------------------------\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "output_folder = f\"umap_three_views_{timestamp}\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "print(f\"ðŸ“ Saving plots to: {output_folder}/\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Load embeddings and compute GLOBAL UMAP @ step 31 (shared space for all 3 figures)\n",
        "# ------------------------------------------------------------\n",
        "emb_per_run, min_T, D = load_embeddings_from_runs(all_runs_pair_order, runs, load_text_per_step=False)\n",
        "\n",
        "step_idx = UMAP_STEP_WANTED\n",
        "if step_idx >= min_T:\n",
        "    print(f\"âš ï¸ Requested step {UMAP_STEP_WANTED}, but min_T={min_T}. Using step {min_T-1} instead.\")\n",
        "    step_idx = min_T - 1\n",
        "\n",
        "# Slice to single step: [N, 1, D]\n",
        "sliced = {rn: emb[:, step_idx:step_idx+1, :] for rn, emb in emb_per_run.items()}\n",
        "pca_components = min(PCA_COMPONENTS, D)\n",
        "\n",
        "E_2d, run_labels, step_labels, chain_indices = compute_global_umap(\n",
        "    sliced,\n",
        "    max_steps=1,\n",
        "    pca_components=pca_components,\n",
        "    umap_n_neighbors=UMAP_N_NEIGHBBORS if 'UMAP_N_NEIGHBBORS' in globals() else UMAP_N_NEIGHBORS,\n",
        "    umap_min_dist=UMAP_MIN_DIST,\n",
        "    umap_random_state=UMAP_SEED,\n",
        "    umap_metric=UMAP_METRIC,\n",
        "    l2_normalize=L2_NORMALIZE,\n",
        ")\n",
        "\n",
        "# --- NEW: shared axis limits (same x/y across all three figures) ---\n",
        "x_min, x_max = float(E_2d[:, 0].min()), float(E_2d[:, 0].max())\n",
        "y_min, y_max = float(E_2d[:, 1].min()), float(E_2d[:, 1].max())\n",
        "x_pad = 0.05 * (x_max - x_min) if x_max > x_min else 1.0\n",
        "y_pad = 0.05 * (y_max - y_min) if y_max > y_min else 1.0\n",
        "X_LIM = (x_min - x_pad, x_max + x_pad)\n",
        "Y_LIM = (y_min - y_pad, y_max + y_pad)\n",
        "\n",
        "run_labels_arr = np.asarray(run_labels)\n",
        "types = np.array([run_to_group.get(rn, \"unknown\") for rn in run_labels_arr])\n",
        "\n",
        "mask_open = types == \"open\"\n",
        "mask_closed = types == \"closed\"\n",
        "mask_unknown = types == \"unknown\"\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Figure 1: All prompts, color-coded Open vs Closed\n",
        "# ------------------------------------------------------------\n",
        "fig1, ax1 = plt.subplots(figsize=(8, 6))\n",
        "ax1.scatter(E_2d[mask_open, 0], E_2d[mask_open, 1], s=POINT_SIZE, alpha=POINT_ALPHA, color=OPEN_COLOR, label=\"Open\")\n",
        "ax1.scatter(E_2d[mask_closed, 0], E_2d[mask_closed, 1], s=POINT_SIZE, alpha=POINT_ALPHA, color=CLOSED_COLOR, label=\"Closed\")\n",
        "if mask_unknown.any():\n",
        "    ax1.scatter(E_2d[mask_unknown, 0], E_2d[mask_unknown, 1], s=POINT_SIZE, alpha=0.35, color=\"gray\", label=\"Unknown\")\n",
        "\n",
        "ax1.set_xlim(*X_LIM)\n",
        "ax1.set_ylim(*Y_LIM)\n",
        "ax1.set_aspect(\"equal\", adjustable=\"box\")  # optional but helps comparison\n",
        "\n",
        "ax1.set_xlabel(\"UMAP 1\")\n",
        "ax1.set_ylabel(\"UMAP 2\")\n",
        "ax1.set_title(\"\")\n",
        "ax1.grid(True, alpha=0.25)\n",
        "ax1.legend(loc=\"best\", frameon=True)\n",
        "fig1.tight_layout(rect=[0, 0, 1, 0.92])\n",
        "set_apa_title(fig1, f\"Semantic Space at Step {step_idx} by Prompt Type\")\n",
        "\n",
        "fn1 = f\"umap_step_{step_idx:02d}_by_type.png\"\n",
        "fig1.savefig(os.path.join(output_folder, fn1), dpi=150, bbox_inches=\"tight\", facecolor=\"white\")\n",
        "plt.close(fig1)\n",
        "print(f\"  âœ“ Saved: {fn1}\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Figure 2: OPEN prompts only (one color per prompt)\n",
        "# ------------------------------------------------------------\n",
        "fig2, ax2 = plt.subplots(figsize=(8, 6))\n",
        "open_run_set = set(open_runs)\n",
        "run_labels_unique = list(dict.fromkeys(run_labels))\n",
        "\n",
        "palette = plt.cm.tab10.colors\n",
        "open_names = [rn for rn in run_labels_unique if rn in open_run_set]\n",
        "open_color_map = {rn: palette[i % len(palette)] for i, rn in enumerate(open_names)}\n",
        "\n",
        "for rn in open_names:\n",
        "    m = run_labels_arr == rn\n",
        "    ax2.scatter(E_2d[m, 0], E_2d[m, 1], s=POINT_SIZE, alpha=POINT_ALPHA, color=open_color_map[rn], label=run_to_prompt.get(rn, rn))\n",
        "\n",
        "ax2.set_xlim(*X_LIM)\n",
        "ax2.set_ylim(*Y_LIM)\n",
        "ax2.set_aspect(\"equal\", adjustable=\"box\")\n",
        "\n",
        "ax2.set_xlabel(\"UMAP 1\")\n",
        "ax2.set_ylabel(\"UMAP 2\")\n",
        "ax2.set_title(\"\")\n",
        "ax2.grid(True, alpha=0.25)\n",
        "ax2.legend(loc=\"best\", fontsize=8, frameon=True)\n",
        "fig2.tight_layout(rect=[0, 0, 1, 0.92])\n",
        "set_apa_title(fig2, f\"Semantic Space at Step {step_idx} for Open Prompts\")\n",
        "\n",
        "fn2 = f\"umap_step_{step_idx:02d}_open_prompts.png\"\n",
        "fig2.savefig(os.path.join(output_folder, fn2), dpi=150, bbox_inches=\"tight\", facecolor=\"white\")\n",
        "plt.close(fig2)\n",
        "print(f\"  âœ“ Saved: {fn2}\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Figure 3: CLOSED prompts only (one color per prompt)\n",
        "# ------------------------------------------------------------\n",
        "fig3, ax3 = plt.subplots(figsize=(8, 6))\n",
        "closed_run_set = set(closed_runs)\n",
        "closed_names = [rn for rn in run_labels_unique if rn in closed_run_set]\n",
        "closed_color_map = {rn: palette[i % len(palette)] for i, rn in enumerate(closed_names)}\n",
        "\n",
        "for rn in closed_names:\n",
        "    m = run_labels_arr == rn\n",
        "    ax3.scatter(E_2d[m, 0], E_2d[m, 1], s=POINT_SIZE, alpha=POINT_ALPHA, color=closed_color_map[rn], label=run_to_prompt.get(rn, rn))\n",
        "\n",
        "ax3.set_xlim(*X_LIM)\n",
        "ax3.set_ylim(*Y_LIM)\n",
        "ax3.set_aspect(\"equal\", adjustable=\"box\")\n",
        "\n",
        "ax3.set_xlabel(\"UMAP 1\")\n",
        "ax3.set_ylabel(\"UMAP 2\")\n",
        "ax3.set_title(\"\")\n",
        "ax3.grid(True, alpha=0.25)\n",
        "ax3.legend(loc=\"best\", fontsize=8, frameon=True)\n",
        "fig3.tight_layout(rect=[0, 0, 1, 0.92])\n",
        "set_apa_title(fig3, f\"Semantic Space at Step {step_idx} for Closed Prompts\")\n",
        "\n",
        "fn3 = f\"umap_step_{step_idx:02d}_closed_prompts.png\"\n",
        "fig3.savefig(os.path.join(output_folder, fn3), dpi=150, bbox_inches=\"tight\", facecolor=\"white\")\n",
        "plt.close(fig3)\n",
        "print(f\"  âœ“ Saved: {fn3}\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Download\n",
        "# ------------------------------------------------------------\n",
        "print(\"\\nâ¬‡ï¸ Downloading 3 files...\")\n",
        "for fn in [fn1, fn2, fn3]:\n",
        "    files.download(os.path.join(output_folder, fn))\n",
        "\n",
        "print(\"\\nâœ… Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdE1v6kkqYm5"
      },
      "source": [
        "### Create horizon widht graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gq_N0r1xo4VI"
      },
      "outputs": [],
      "source": [
        "# Plot pairwise cosine distance (horizon width) for selected Open vs Closed prompts\n",
        "# FIRST 5 steps (0..4): one figure for MEAN, one for MAX\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.lines import Line2D\n",
        "\n",
        "from src.protoInterpretation import run_name_to_display, load_run_by_name\n",
        "\n",
        "if \"runs\" not in globals():\n",
        "    raise RuntimeError(\"`runs` is not defined. Run the scan_runs cell first.\")\n",
        "\n",
        "PROMPT_PAIRS = [\n",
        "    (\"A bat is\", \"A pencil is\"),\n",
        "    (\"The woman in the blue dress\", \"Napoleon is\"),\n",
        "    (\"I saw\", \"Photosynthesis is the process where\"),\n",
        "    (\"Something happens when there exists\", \"The declaration of Independence formally\"),\n",
        "    (\"The man\", \"Photosynthesis is\"),\n",
        "    (\"The man in the street\", \"Erosion is\"),\n",
        "]\n",
        "\n",
        "OPEN_COLOR = \"#1f77b4\"\n",
        "CLOSED_COLOR = \"#ff7f0e\"\n",
        "OPEN_STYLE = dict(color=OPEN_COLOR, linestyle=\"-\", linewidth=2, alpha=0.9)\n",
        "CLOSED_STYLE = dict(color=CLOSED_COLOR, linestyle=\"--\", linewidth=2, alpha=0.9)\n",
        "\n",
        "def _norm(s: str) -> str:\n",
        "    return \" \".join(str(s).strip().lower().split())\n",
        "\n",
        "open_keys = [_norm(p[0]) for p in PROMPT_PAIRS]\n",
        "closed_keys = [_norm(p[1]) for p in PROMPT_PAIRS]\n",
        "key_to_type = {k: \"open\" for k in open_keys}\n",
        "key_to_type.update({k: \"closed\" for k in closed_keys})\n",
        "\n",
        "# Restrict candidate runs to dropdown selection if present; else all runs\n",
        "candidate_run_names = list(runs.keys())\n",
        "if \"dropdowns\" in globals():\n",
        "    picked = [getattr(d, \"value\", \"\") for d in dropdowns if getattr(d, \"value\", \"\")]\n",
        "    picked = list(dict.fromkeys([p for p in picked if p]))\n",
        "    if picked:\n",
        "        candidate_run_names = picked\n",
        "\n",
        "# Pick latest run per prompt (by timestamp sort in folder name)\n",
        "runs_for_key = {k: [] for k in set(open_keys + closed_keys)}\n",
        "for rn in candidate_run_names:\n",
        "    k = _norm(run_name_to_display(rn))\n",
        "    if k in runs_for_key:\n",
        "        runs_for_key[k].append(rn)\n",
        "\n",
        "chosen_for_key = {k: max(v) for k, v in runs_for_key.items() if v}\n",
        "\n",
        "missing = [k for k in set(open_keys + closed_keys) if k not in chosen_for_key]\n",
        "if missing:\n",
        "    print(\"âš ï¸ Missing runs for:\", missing)\n",
        "\n",
        "# Load metrics\n",
        "metrics_for_key = {}\n",
        "for k, rn in chosen_for_key.items():\n",
        "    _, m = load_run_by_name(rn, runs, compute_metrics=True)\n",
        "    metrics_for_key[k] = m\n",
        "\n",
        "T_SHOW = 5  # steps 0..4\n",
        "\n",
        "def plot_width(which: str):\n",
        "    fig, ax = plt.subplots(figsize=(8, 4))\n",
        "    for k, m in metrics_for_key.items():\n",
        "        y_full = m.width.mean_dist if which == \"mean\" else m.width.max_dist\n",
        "        y = y_full[:T_SHOW] if len(y_full) >= T_SHOW else y_full\n",
        "        g = key_to_type.get(k, \"unknown\")\n",
        "        if g == \"open\":\n",
        "            ax.plot(np.arange(len(y)), y, **OPEN_STYLE)\n",
        "        elif g == \"closed\":\n",
        "            ax.plot(np.arange(len(y)), y, **CLOSED_STYLE)\n",
        "\n",
        "    ax.set_xlabel(\"Step (first 5)\")\n",
        "    ax.set_ylabel(\"Cosine distance\")\n",
        "    ax.set_title(f\"Pairwise Cosine Distance ({which.upper()}) for Open vs Closed Prompts (Steps 0â€“4)\")\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "    handles = [\n",
        "        Line2D([0], [0], **OPEN_STYLE, label=\"Open prompts\"),\n",
        "        Line2D([0], [0], **CLOSED_STYLE, label=\"Closed prompts\"),\n",
        "    ]\n",
        "    ax.legend(handles=handles, loc=\"best\", frameon=True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_width(\"mean\")\n",
        "plot_width(\"max\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psEPyk5JFYAv"
      },
      "source": [
        "# Print all sqeunces from a prompt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSZeGx1MFf5v"
      },
      "outputs": [],
      "source": [
        "# Prefer installed package name; fall back to repo import\n",
        "try:\n",
        "    from protoInterpretation import load_run_by_name\n",
        "except ImportError:\n",
        "    from src.protoInterpretation import load_run_by_name\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "# Pick selected run from dropdowns\n",
        "run_name = next((d.value for d in dropdowns if d.value), None)\n",
        "if not run_name:\n",
        "    raise RuntimeError(\"Select at least 1 run in the dropdowns above.\")\n",
        "\n",
        "batch, _ = load_run_by_name(run_name, runs, compute_metrics=False)\n",
        "\n",
        "# Decide how many chains exist\n",
        "N = None\n",
        "if batch.text_sequences is not None and len(batch.text_sequences) > 0:\n",
        "    N = len(batch.text_sequences)\n",
        "elif batch.text_per_step is not None and len(batch.text_per_step) > 0:\n",
        "    N = len(batch.text_per_step)\n",
        "else:\n",
        "    raise RuntimeError(\n",
        "        \"This run has no decoded text (text_sequences/text_per_step missing). \"\n",
        "        \"Re-run sampling with a newer version or decode token_ids with a tokenizer.\"\n",
        "    )\n",
        "\n",
        "print(f\"Run: {run_name} | N={N} chains\")\n",
        "\n",
        "# How many chains to render at once\n",
        "K = 20  # change this\n",
        "\n",
        "start_slider = widgets.IntSlider(min=0, max=max(0, N - 1), step=1, description=\"Start\")\n",
        "out = widgets.Output()\n",
        "\n",
        "def get_full_chain(i: int) -> str:\n",
        "    # Preferred: full final decoded chain\n",
        "    if batch.text_sequences is not None and i < len(batch.text_sequences):\n",
        "        return batch.text_sequences[i]\n",
        "\n",
        "    # Fallback: last step in per-step cumulative text\n",
        "    if batch.text_per_step is not None and i < len(batch.text_per_step) and len(batch.text_per_step[i]) > 0:\n",
        "        return batch.text_per_step[i][-1]\n",
        "\n",
        "    return \"[No decoded full-chain text available]\"\n",
        "\n",
        "def render(_=None):\n",
        "    out.clear_output()\n",
        "    with out:\n",
        "        start = start_slider.value\n",
        "        end = min(start + K, N)\n",
        "        for i in range(start, end):\n",
        "            print(f\"{get_full_chain(i)}\")\n",
        "            print()\n",
        "\n",
        "start_slider.observe(render, names=\"value\")\n",
        "render()\n",
        "display(start_slider, out)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Hzk5cVtzYVZL",
        "Rglsq_tk7GAz",
        "Wpsu1nA0BZo4",
        "n93ywRqzJSjJ"
      ],
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
